AWSTemplateFormatVersion: '2010-09-09'
Description: 'GXO Signify Pilot - S3 Data Lake Infrastructure'

Parameters:
  Environment:
    Type: String
    Default: pilot
    AllowedValues: [pilot, production]

Resources:
  # S3 Data Lake Bucket (without notification initially)
  DataLakeBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "gxo-signify-${Environment}-${AWS::AccountId}"
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldVersions
            Status: Enabled
            NoncurrentVersionExpirationInDays: 30
          - Id: ArchiveOldData
            Status: Enabled
            Transitions:
              - TransitionInDays: 90
                StorageClass: STANDARD_IA
              - TransitionInDays: 180
                StorageClass: GLACIER

  # Lambda function for S3 event processing (simplified)
  DataProcessorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "gxo-signify-${Environment}-data-processor"
      Runtime: python3.11
      Handler: index.lambda_handler
      Role: !GetAtt DataProcessorRole.Arn
      Timeout: 300
      MemorySize: 512
      Environment:
        Variables:
          BUCKET_NAME: !Ref DataLakeBucket
          ENVIRONMENT: !Ref Environment
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          
          def lambda_handler(event, context):
              """
              Process S3 upload events - placeholder for Phase 1
              """
              print(f"Data upload detected. Processing {len(event['Records'])} files...")
              
              for record in event['Records']:
                  bucket = record['s3']['bucket']['name']
                  key = record['s3']['object']['key']
                  
                  print(f"File uploaded: s3://{bucket}/{key}")
                  
                  # TODO: Trigger Glue job in Phase 2
              
              return {
                  'statusCode': 200,
                  'body': json.dumps('Data upload logged successfully')
              }

  # IAM Role for Lambda
  DataProcessorRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "gxo-signify-${Environment}-data-processor-role"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                Resource: !Sub "arn:aws:s3:::gxo-signify-${Environment}-${AWS::AccountId}/*"
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource: !Sub "arn:aws:s3:::gxo-signify-${Environment}-${AWS::AccountId}"
  # Lambda permission for S3
  LambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref DataProcessorFunction
      Principal: s3.amazonaws.com
      SourceArn: !Sub "arn:aws:s3:::gxo-signify-${Environment}-${AWS::AccountId}/*"

Outputs:
  DataLakeBucketName:
    Description: S3 Data Lake Bucket Name
    Value: !Ref DataLakeBucket
    Export:
      Name: !Sub "${AWS::StackName}-DataLakeBucket"
      
  DataProcessorFunctionArn:
    Description: Data Processor Lambda Function ARN
    Value: !GetAtt DataProcessorFunction.Arn
    Export:
      Name: !Sub "${AWS::StackName}-DataProcessorFunction"